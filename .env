# HATA ML Service Environment Variables
# Using HuggingFace Inference API (optimized for Render free tier)

# Server
PORT=5000
HOST=0.0.0.0
RELOAD=false

# Model Configuration - HuggingFace Inference API
MODEL_NAME=msmaje/afroBERTaphdmodel500mb
HF_API_ENDPOINT=https://api-inference.huggingface.co/models/msmaje/afroBERTaphdmodel500mb
USE_HF_INFERENCE_API=true
HF_TOKEN=your_hf_token_here
INFERENCE_API_TIMEOUT=30

# CORS - Allow local development and production frontend
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,https://hatafrontend-1fv4sh97i-musa-adamus-projects.vercel.app,https://hatabackend.onrender.com

# Explainability (simplified - LIME still available if needed)
LIME_NUM_SAMPLES=500
LIME_NUM_FEATURES=10

# Logging
LOG_LEVEL=INFO
